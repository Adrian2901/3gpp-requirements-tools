{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3REQ system\n",
    "\n",
    "Requirement analysis system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from docx2python import docx2python\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total time\n",
    "execution_time = end_time - start_time\n",
    "formatted_execution_time = \"{:.1f}\".format(execution_time)\n",
    "print(\"Execution time:\", formatted_execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: List the documents's sections with \"latency\"\n",
    "\n",
    "In the first step, we go through the documents in the folder \"input_standards\" and we extract which sections of these documents contain th word \"latency\". We store the results in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLatencySections(doc):\n",
    "    strSectionTitle = \"\"\n",
    "    dictSections = {}\n",
    "    listLatency = []\n",
    "\n",
    "    doc_result = docx2python(doc,paragraph_styles = True, html=True)\n",
    "\n",
    "    # we iterate over all lines\n",
    "    # look for the section titles (which have the tag <h1>, <h2>, <h3>, etc.)\n",
    "    # then we add the content of each section to the dictionary\n",
    "    # and if there is a word \"latency\" somewhere in the section, we add the section title to the listLatency\n",
    "    for oneLine in doc_result.text.split('\\n'):\n",
    "        if \"<h\" in oneLine:\n",
    "            strSectionTitle = oneLine\n",
    "            dictSections[strSectionTitle] = []\n",
    "\n",
    "        if strSectionTitle != \"\":  \n",
    "            dictSections[strSectionTitle].append(oneLine)\n",
    "\n",
    "        if \"latency\" in oneLine: \n",
    "            listLatency.append(strSectionTitle)\n",
    "            \n",
    "    # remove the keys from the dictionary if they are not part of the listLatency\n",
    "    # as we want to get only the relevant sections, i.e., the one with the word latency\n",
    "    for key in list(dictSections.keys()):\n",
    "        if key not in listLatency:\n",
    "            del dictSections[key]\n",
    "\n",
    "    # return the dictionary with the relevant sections\n",
    "    return dictSections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docInputFolder = \"./input_standards\"\n",
    "\n",
    "# this is the return list of all the lines in the document\n",
    "lstAllLines = []\n",
    "\n",
    "# for each .docx file in the input folder\n",
    "# extract the sections with latency using the extractLatencySections function\n",
    "# and print the sections\n",
    "for doc in os.listdir(docInputFolder):    \n",
    "\n",
    "    if doc.endswith(\".docx\"):\n",
    "\n",
    "        # since things can go wrong with the latency library, \n",
    "        # we use a try except block to avoid the program to stop\n",
    "        try: \n",
    "            dictSections = extractLatencySections(os.path.join(docInputFolder, doc))\n",
    "        \n",
    "            # we list the content\n",
    "            # as a long list of sections \n",
    "            for key in dictSections:\n",
    "\n",
    "                lstOneLine = [key, doc]\n",
    "\n",
    "                for line in dictSections[key]:\n",
    "                    lstOneLine.append(line)\n",
    "                    \n",
    "                lstAllLines.append(lstOneLine)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {doc}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# list with all embeddings for the sections\n",
    "lstEmbeddings = []\n",
    "\n",
    "for oneLine in lstAllLines:\n",
    "\n",
    "    # the content of the section starts on the third position of the list\n",
    "    sentences = oneLine[3:]\n",
    "\n",
    "    # Sentences are encoded by calling model.encode()\n",
    "    embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Print the average embeddings for all the sentences \n",
    "    # in this section\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    lstOneLine = [oneLine[0], oneLine[1], 2, str(sentences).replace(\"$\", \"_\").replace(\"\\n\", \"_\"), avg_embedding]\n",
    "\n",
    "    lstEmbeddings.append(lstOneLine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot these average embeddings using t-SNE\n",
    "\n",
    "# we create a list with the embeddings\n",
    "lstEmbeddingsNP = np.array([x[4] for x in lstEmbeddings])\n",
    "\n",
    "# we use t-SNE to reduce the dimensionality of the embeddings\n",
    "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(lstEmbeddingsNP)\n",
    "\n",
    "# we plot the t-SNE results\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.scatter(tsne_results[:,0], tsne_results[:,1])\n",
    "\n",
    "# Add labels to each dot\n",
    "for i, label in enumerate([x[0] for x in lstEmbeddings]):\n",
    "    plt.text(tsne_results[i, 0], tsne_results[i, 1], label[3:10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find the relevant sections\n",
    "\n",
    "In this step, we take the sections identified in Step 1 and we compare them to a list of right and wrong requirements. The list is stored in the file List.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file List.xlsx using pandas\n",
    "# and read the workshop NR\n",
    "df = pd.read_excel(\"List.xlsx\", sheet_name=\"R_NR\")\n",
    "\n",
    "# convert the dataframe to a list of lists\n",
    "lstReference = df.values.tolist()\n",
    "\n",
    "lstReference[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with all embeddings for the sections\n",
    "lstEmbeddingsRef = []\n",
    "\n",
    "for oneLine in lstReference:\n",
    "\n",
    "    # the content of the section starts on the third position of the list\n",
    "    sentences = oneLine[0]\n",
    "\n",
    "    # Sentences are encoded by calling model.encode()\n",
    "    embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Print the average embeddings for all the sentences \n",
    "    # in this section\n",
    "    avg_embedding = embeddings\n",
    "    \n",
    "    lstOneLine = [oneLine[0], 'REF', oneLine[1], oneLine[1], avg_embedding]\n",
    "\n",
    "    lstEmbeddingsRef.append(lstOneLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two lists\n",
    "lstEmbeddingsAll = lstEmbeddings + lstEmbeddingsRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot these average embeddings using t-SNE\n",
    "\n",
    "# we create a list with the embeddings\n",
    "lstEmbeddingsNP = np.array([x[4] for x in lstEmbeddingsAll])\n",
    "\n",
    "# we use t-SNE to reduce the dimensionality of the embeddings\n",
    "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(lstEmbeddingsNP)\n",
    "\n",
    "# Create a color map based on x[2]\n",
    "color_map = {0: 'red', 1: 'green', 2: 'blue'}\n",
    "colors = [color_map[x[2]] for x in lstEmbeddingsAll]\n",
    "\n",
    "# we plot the t-SNE results\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.scatter(tsne_results[:,0], tsne_results[:,1],c=colors, s=100, alpha=0.5)\n",
    "\n",
    "# Add labels to each dot\n",
    "for i, label in enumerate([x[0] for x in lstEmbeddingsAll]):\n",
    "    plt.text(tsne_results[i, 0], tsne_results[i, 1], label[:10]+'...')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# for each line in lstEmbeddings\n",
    "# we calculate the euclidean distance with each line in lstEmbeddingsRef\n",
    "\n",
    "lstDistPos = []\n",
    "lstDistNeg = []\n",
    "\n",
    "lstRelevant = []\n",
    "\n",
    "for oneLine in lstEmbeddings:    \n",
    "    for oneLineRef in lstEmbeddingsRef:\n",
    "        if oneLineRef[2] == 1:\n",
    "            # euclidean distance between the two embeddings\n",
    "            dist = euclidean_distances([oneLine[4]], [oneLineRef[4]])\n",
    "            lstDistPos.append(dist[0][0])\n",
    "        if oneLineRef[2] == 0:\n",
    "            # euclidean distance between the two embeddings\n",
    "            dist = euclidean_distances([oneLine[4]], [oneLineRef[4]])\n",
    "            lstDistNeg.append(dist[0][0])\n",
    "    \n",
    "    # now calculate the average for both lists\n",
    "    avgDistPos = np.mean(lstDistPos)\n",
    "    avgDistNeg = np.mean(lstDistNeg)\n",
    "\n",
    "    if avgDistPos < avgDistNeg:\n",
    "        #print(f\"Section {oneLine[0]} is relevant\")\n",
    "        # add the class to the list\n",
    "        oneLine.append(1)\n",
    "        lstRelevant.append(oneLine)\n",
    "    else:\n",
    "        #print(f\"Section {oneLine[0]} is not relevant\")\n",
    "        # add the class to the list\n",
    "        oneLine.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we save all the relevant sections to an Excel file\n",
    "# and the non-relevant ones too\n",
    "import pandas as pd\n",
    "\n",
    "dfOutput = pd.DataFrame(lstEmbeddings, columns=[\"Section\", \"Document\", \"Class\", \"Content\", \"Embedding\", \"Relevance\"])\n",
    "\n",
    "dfOutput.to_excel(\"./output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Find which requirements are impacted\n",
    "\n",
    "In this step, we compare the relevant sections with the existing requirements. Based on the distance, we can determine which requirements are impacted. The requirements are provided as a separete list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage relevant: {len(lstRelevant)/len(lstEmbeddings)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the requirements from the excel file requirements.xlsx, worksheet LR\n",
    "#df = pd.read_excel(\"requirements.xlsx\", sheet_name=\"LR\")\n",
    "df = pd.read_excel(\"List.xlsx\", sheet_name=\"LR\")\n",
    "\n",
    "# convert to list\n",
    "lstRequirements = df.values.tolist()\n",
    "lstRequirements[0]\n",
    "\n",
    "# now we calculate the embeddings for each of these requirements\n",
    "lstEmbeddingsReq = []\n",
    "\n",
    "for oneLine in lstRequirements:\n",
    "    \n",
    "        # the content of the section starts on the third position of the list\n",
    "        sentences = oneLine[1]\n",
    "    \n",
    "        # Sentences are encoded by calling model.encode()\n",
    "        embeddings = model.encode(sentences)\n",
    "        \n",
    "        # Print the average embeddings for all the sentences \n",
    "        # in this section\n",
    "        avg_embedding = embeddings\n",
    "        \n",
    "        lstOneLine = [oneLine[0], 'latency', oneLine[1], oneLine[1], avg_embedding]\n",
    "    \n",
    "        lstEmbeddingsReq.append(lstOneLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we calculate the euclidean distance between the requirements and the sections\n",
    "# that are relevant\n",
    "lstDist = []\n",
    "lstRelevantDist = []\n",
    "\n",
    "for oneLine in lstRelevant:\n",
    "    for oneLineReq in lstEmbeddingsReq:\n",
    "        # euclidean distance between the two embeddings\n",
    "        dist = euclidean_distances([oneLine[4]], [oneLineReq[4]])\n",
    "        lstDist.append([oneLine[0], oneLine[1], oneLineReq[0], dist[0][0]])\n",
    "\n",
    "# now we sort the list by the distance\n",
    "lstDist.sort(key=lambda x: x[2])\n",
    "\n",
    "# and we print them\n",
    "for i in range(len(lstDist)):\n",
    "    print(f\"Section {lstDist[i][0]} is close to requirement {lstDist[i][2]} with distance {lstDist[i][3]:.2f}\")\n",
    "    # add this to a list\n",
    "    lstRelevantDist.append([lstDist[i][0], lstDist[i][1], lstDist[i][2], lstDist[i][3]])\n",
    "\n",
    "# save the list to an Excel file\n",
    "dfOutput = pd.DataFrame(lstRelevantDist, columns=[\"Section\", \"Document\", \"Requirement\", \"Distance\"])\n",
    "\n",
    "dfOutput.to_excel(\"./output_requirements_distances.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Find if it is a new requirement\n",
    "\n",
    "In the last step, we look at the distances and then we find if they too far away from the existing requirements. If they are, we can consider them as new requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
